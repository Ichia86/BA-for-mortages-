{"cells":[{"cell_type":"markdown","metadata":{"id":"0sXdGe8BfYDf"},"source":["## Import library"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SiMquELgp5jo"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","pd.set_option('display.max_columns', 500)"]},{"cell_type":"markdown","metadata":{"id":"k1oMrC91fYDj"},"source":["## Data Loading"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":311},"executionInfo":{"elapsed":570,"status":"error","timestamp":1733089591141,"user":{"displayName":"Yulin Tang","userId":"12638252677395551974"},"user_tz":300},"id":"wAXOuMGbp99g","outputId":"9ce6b023-86b3-4c12-d8d2-24c608653361"},"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: 'df_1999_to_2024.csv'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-0c56830eb660>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'df_1999_to_2024.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'df_1999_to_2024.csv'"]}],"source":["df = pd.read_csv('df_1999_to_2024.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D3owXNu6qg2n"},"outputs":[],"source":["df.info()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yKKHyNvMq9pC"},"outputs":[],"source":["df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bxNrnZlufYDl"},"outputs":[],"source":["df.columns"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IvSYZwDNql_9"},"outputs":[],"source":["# drop the first index column\n","df.drop(columns=['Unnamed: 0'], inplace=True)\n","df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"igsYsT3OrDZG"},"outputs":[],"source":["# Building next month status\n","#df = df.sort_values(by=['Loan Sequence Number', 'Monthly Reporting Period'])\n","#print(df['Monthly Reporting Period'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aJk9tbmJsazn"},"outputs":[],"source":["# to organize the format which will make the conversion easier\n","df['Monthly Reporting Period'] = df['Monthly Reporting Period'].str[:10]\n","df['Monthly Reporting Period']\n","# Convert to datetime while coercing invalid formats\n","df['Monthly Reporting Period'] = pd.to_datetime(\n","    df['Monthly Reporting Period'], errors='coerce')\n","\n","# Format back to date only (as string format YYYY-MM)\n","df['Monthly Reporting Period'] = df['Monthly Reporting Period'].dt.strftime('%Y-%m')"]},{"cell_type":"code","source":["df = df.sort_values(['Loan Sequence Number', 'Monthly Reporting Period'])"],"metadata":{"id":"X19BxUPc_0xj"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z7Odh36GtGLk"},"outputs":[],"source":["print(df['Monthly Reporting Period'].isna().sum())"]},{"cell_type":"code","source":["df"],"metadata":{"id":"DQI7K6er_3ab"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2_tNmvujtwAM"},"outputs":[],"source":["# Add a column which represents the loan's next month delinquency status, which will be the\n","df = df.sort_values(by=['Loan Sequence Number', 'Monthly Reporting Period'], ascending=True)\n","df['Next Month Status'] = df.groupby('Loan Sequence Number')['Current Loan Delinquency Status'].shift(-1)\n","print(df['Next Month Status'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AryII5xefYDn"},"outputs":[],"source":["df['Monthly Reporting Period'][df['Loan Sequence Number'] == 'F99Q10404048']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JzxuzoqKfYDn"},"outputs":[],"source":["df[df['Loan Sequence Number'] == 'F99Q10404048']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"znXbiFjEfYDo"},"outputs":[],"source":["test_1 = df[df['Next Month Status'].isna()]"]},{"cell_type":"code","source":["test_1"],"metadata":{"id":"PGaAWrzZFAey"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iBUPjWgIfYDo"},"outputs":[],"source":["test_1['Zero Balance Code'].value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Dg_R25zQZkU6"},"outputs":[],"source":["# create a new column to represent prepayment tag\n","df['Prepayment tag'] = df['Zero Balance Code'].apply(\n","    lambda x: 1 if x == 1.0 else 0\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ti7BBRIhfYDo"},"outputs":[],"source":["df['Prepayment tag'].value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w9Jl3qIxfYDo"},"outputs":[],"source":["# check those record whose Next Month Status is not null but shows prepaid\n","remove_duplicate = df[(df['Prepayment tag'] == 1) & (df['Next Month Status'].notna())]\n","remove_duplicate\n","remove_index = remove_duplicate.index"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AAIO7_ZOfYDo"},"outputs":[],"source":["# Tried several one and realized that the last one have duplicate\n","df['Monthly Reporting Period'][df['Loan Sequence Number'] == 'F22Q10579658']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cYBLSUz5fYDo"},"outputs":[],"source":["df = df.drop(remove_index, axis=0)\n","df.info()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7dUp6xCDfYDp"},"outputs":[],"source":["# save the records which Next Month Status is null value\n","test_2 = df[df['Next Month Status'].isna()]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QVSaKicefYDp"},"outputs":[],"source":["# check the zero balance code for these records\n","test_2['Zero Balance Code'].value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Kn-30UMSfYDp"},"outputs":[],"source":["# null value match the prepayment tag\n","df['Prepayment tag'].value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tc2MgAxtfYDp"},"outputs":[],"source":["# replace the na with 4 to represent prepayment if zero balance code shows 1.0, else Next Month Status = 3\n","df['Next Month Status'] = df['Next Month Status'].fillna(\n","    df.apply(lambda row: 4 if row['Prepayment tag'] == 1.0 else np.nan, axis=1)\n",")\n"]},{"cell_type":"code","source":["df['Next Month Status'].isna().sum()"],"metadata":{"id":"WeYcFVZ5_fpG"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6R-CUNIrfYDp"},"outputs":[],"source":["# check if they are correctly filled\n","(df['Prepayment tag'][df['Next Month Status'] == 4] == 1).sum() # match the occurence"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-oziz8GiZkU6"},"outputs":[],"source":["# convert the data type for modeling later\n","df['Next Month Status'] = df['Next Month Status'].astype('int')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nbdhNLB0ZkU6"},"outputs":[],"source":["df.info()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iWQgHKzsfYDq"},"outputs":[],"source":["df['Next Month Status'].value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CG0tLj4wfYDq"},"outputs":[],"source":["# Because we only have to predict 0, 1, 2, 3 categories\n","df['Next Month Status'] = df['Next Month Status'].apply(\n","        lambda x: 3 if x > 4 else x)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"66De9FyofYDq"},"outputs":[],"source":["df['Next Month Status'].value_counts()"]},{"cell_type":"markdown","metadata":{"id":"ewr4hI2VfYDq"},"source":["## Data Cleaning"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KOIhxKHnZkU7"},"outputs":[],"source":["# check null value\n","df.isna().sum()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FWj5cP9EfYDq"},"outputs":[],"source":["# save a copy for reference\n","df_copy = df.copy()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iiKDpi8JfYDr"},"outputs":[],"source":["# check the columns which have high percentage of null values\n","# Calculate the percentage of missing values\n","null_percentage = df.isna().sum() / len(df) * 100\n","null_percentage"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mTUbSS10fYDr"},"outputs":[],"source":["# First, check those columns which null value percentage higher than 50%\n","percentage_50 = null_percentage[null_percentage>50]\n","percentage_50"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xp5BTuBcfYDr"},"outputs":[],"source":["# Save the columns in percentage_50 and remove certain columns which might be good to keep\n","columns_to_drop = percentage_50.index.drop(['Zero Balance Code', 'Borrower Assistance Status Code', 'Delinquency Due to Disaster'])\n","columns_to_drop"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xb0ZgvqBfYDr"},"outputs":[],"source":["# drop the columns we decide to drop first\n","# These columns have more than 50% null values, but we keep 'Zero Balance Code' since it might be a siginificant indicator of delinquency status\n","df = df.drop(columns=columns_to_drop)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jBVhxUU7fYDr"},"outputs":[],"source":["# Also, check those columns which null value percentage lower 50%\n","percentage_lower_50 = null_percentage[null_percentage<=50]\n","percentage_lower_50"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oSNP8IqvfYDw"},"outputs":[],"source":["# Number of Borrowers\n","# Before 2018 Q1, more than 1 borrower would only represent 02\n","# After 2018 Q1, the number shows the real number of borrowers\n","# First, check how many unknown borrowers\n","df[(df['Number of Borrowers'] == 99) | df['Number of Borrowers'].isna()]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T9OtENXrfYDw"},"outputs":[],"source":["# check loans before 2018Q1 in different Loan Purpose\n","df_before2018Q1 = df[df['Monthly Reporting Period'] <= '2018-03']\n","df_before2018Q1.groupby('Loan Purpose')['Number of Borrowers'].value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"thy-mm1afYDx"},"outputs":[],"source":["# check loans after 2018Q1 in different Loan Purpose\n","df_after2018Q1 = df[df['Monthly Reporting Period'] > '2018-03']\n","df_after2018Q1.groupby('Loan Purpose')['Number of Borrowers'].value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GW9pL-5ifYDx"},"outputs":[],"source":["# Seems like most of the number of borrowers is 1, so we fill null value and 99 with '1' (also a median)\n","num_borowers_median = df['Number of Borrowers'].median()\n","df['Number of Borrowers'] = df['Number of Borrowers'].apply(\n","        lambda x: num_borowers_median if pd.isna(x) or x == 99 else x)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HPdxaIKCfYDx"},"outputs":[],"source":["df['Number of Borrowers'].value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oVtgULCZfYDx"},"outputs":[],"source":["# Credit Score\n","# If Credit Score > 850 or < 300 would shown 9999, meaning not available\n","# Fill Credit score with median\n","credit_score_median = df['Credit Score'].median()\n","df['Credit Score'] = df['Credit Score'].apply(\n","        lambda x: credit_score_median if pd.isna(x) or x == 9999 else x)\n","print(df['Credit Score'].isna().sum())\n","print((df['Credit Score'] == 9999).sum())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PdhgjDX-fYDx"},"outputs":[],"source":["df['Credit Score'].describe()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p1sVybc1fYDx"},"outputs":[],"source":["import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","# Assuming 'Credit Score' is the column that holds the credit score values in your DataFrame\n","plt.figure(figsize=(8, 6))\n","\n","# Create the box plot\n","sns.boxplot(x=df['Credit Score'])\n","\n","# Adding labels and title\n","plt.title('Box Plot of Credit Scores')\n","plt.xlabel('Credit Score')\n","\n","# Show the plot\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rKeibzkgfYDx"},"outputs":[],"source":["# Create a new column to represent how good is the credit score group\n","'''\n","df['Credit Score Group'] = df['Credit Score'].apply(\n","    lambda x: 'Poor' if 300 <= x < 580 else\n","              'Fair' if 580 <= x < 670 else\n","              'Good' if 670 <= x < 740 else\n","              'Very Good' if 740 <= x < 800 else\n","              'Exceptional' if 800 <= x <= 850 else 'Unknown'\n",")\n","'''"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xb4pgSvCfYDx"},"outputs":[],"source":["#df['Credit Score Group'].value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GHF3McWJZkU7"},"outputs":[],"source":["# Original Debt-to-Income (DTI) Ratio\n","# Create a new column to show the level of DTI (Feature Engineering)\n","# Using a lambda function to categorize based on DTI ratio\n","df['Original Debt-to-Income (DTI) Ratio_Level'] = df['Original Debt-to-Income (DTI) Ratio'].apply(\n","    lambda x: 'Low' if x <= 35 else\n","              'Middle' if 35 < x <= 49 else\n","              'High' if 50 <= x <= 49 else\n","              'Very High' if x == 999 else None\n",")\n","\n","#df['Original Debt-to-Income (DTI) Ratio'].describe()\n","#df['Original Debt-to-Income (DTI) Ratio'] = df['Original Debt-to-Income (DTI) Ratio'].fillna(df['Original Debt-to-Income (DTI) Ratio'].median())\n","df['Original Debt-to-Income (DTI) Ratio_Level'].value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GQsb0pJ7fYDy"},"outputs":[],"source":["# Fill the null value with \"Middle\" (Mode)\n","df['Original Debt-to-Income (DTI) Ratio_Level'] = df['Original Debt-to-Income (DTI) Ratio_Level'].fillna('Middle')\n","print(df['Original Debt-to-Income (DTI) Ratio_Level'].value_counts())\n","print(df['Original Debt-to-Income (DTI) Ratio_Level'].isna().sum())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bfRaJbXGfYDy"},"outputs":[],"source":["# tempararily try to remove 'Original Debt-to-Income (DTI) Ratio' column and keep 'Original Debt-to-Income (DTI) Ratio_Level'\n","df = df.drop('Original Debt-to-Income (DTI) Ratio', axis=1)\n","df.columns"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-Gxm7pOFfYDy"},"outputs":[],"source":["# First Time Homebuyer Flag: fill null value with mode\n","first_time_flag_mode = df['First Time Homebuyer Flag'].mode()[0]\n","df['First Time Homebuyer Flag'] = df['First Time Homebuyer Flag'].apply(\n","        lambda x: first_time_flag_mode if pd.isna(x) or x == 'Not Available' else x)\n","df['First Time Homebuyer Flag'].value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Fa3LgpQqfYDy"},"outputs":[],"source":["# fill \"not available\" with null value in Loan Purpose\n","df['Loan Purpose'] = df['Loan Purpose'].fillna('Not Available')\n","print(df['Loan Purpose'].isna().sum())\n","df['Loan Purpose'].value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H_ZEspADfYDy"},"outputs":[],"source":["# Occupancy Status\n","print(df['Occupancy Status'].isna().sum())\n","df['Occupancy Status'].value_counts()\n","\n","# fill \"not available\" with null value in Occupancy Status\n","df['Occupancy Status'] = df['Occupancy Status'].fillna('Not Available')\n","print(df['Occupancy Status'].isna().sum())\n","df['Occupancy Status'].value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w5RkBML7fYDy"},"outputs":[],"source":["# Channel\n","print(df['Channel'].isna().sum())\n","df['Channel'].value_counts()\n","# fill \"not available\" with null value in Occupancy Status\n","df['Channel'] = df['Channel'].fillna('Not Available')\n","print(df['Channel'].isna().sum())\n","df['Channel'].value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W6owiZiXfYDz"},"outputs":[],"source":["# Property Type\n","print(df['Property Type'].isna().sum())\n","df['Property Type'].value_counts()\n","# fill \"not available\" with null value in Property Type\n","df['Property Type'] = df['Property Type'].fillna('Not Available')\n","print(df['Property Type'].isna().sum())\n","df['Property Type'].value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OhuZg-L3fYDz"},"outputs":[],"source":["# Amortization Type (Formerly Product Type)\n","df['Amortization Type (Formerly Product Type)'].value_counts()\n","df['Amortization Type (Formerly Product Type)'].isna().sum()\n","# fill \"not available\" with null value in Amortization Type (Formerly Product Type)\n","df['Amortization Type (Formerly Product Type)'] = df['Amortization Type (Formerly Product Type)'].fillna('Not Available')\n","print(df['Amortization Type (Formerly Product Type)'].isna().sum())\n","df['Amortization Type (Formerly Product Type)'].value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TBiD_MlafYDz"},"outputs":[],"source":["# Amortization Type (Formerly Product Type)\n","df['Interest Only (I/O) Indicator'].value_counts()\n","df['Interest Only (I/O) Indicator'].isna().sum()\n","# fill \"not available\" with null value in Amortization Type (Formerly Product Type)\n","df['Interest Only (I/O) Indicator'] = df['Interest Only (I/O) Indicator'].fillna('Not Available')\n","print(df['Interest Only (I/O) Indicator'].isna().sum())\n","df['Interest Only (I/O) Indicator'].value_counts()"]},{"cell_type":"markdown","metadata":{"id":"nm3ToBShfYDz"},"source":["## From here, have not check each one"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dPz_E-rcZkU7"},"outputs":[],"source":["#使用相關欄位推算缺失值：\n","#Estimated Loan-to-Value (ELTV) 以 Original Combined Loan-to-Value (CLTV) 填補。\n","df['Estimated Loan-to-Value (ELTV)'] = df['Estimated Loan-to-Value (ELTV)'].fillna(df['Original Combined Loan-to-Value (CLTV)'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hkBq7TqsfYDz"},"outputs":[],"source":["df[df['Original Combined Loan-to-Value (CLTV)'].isna()]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OV2rfJFVfYD0"},"outputs":[],"source":["df['Original Combined Loan-to-Value (CLTV)'].describe()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s8LgGVkVfYD0"},"outputs":[],"source":["df[df['Estimated Loan-to-Value (ELTV)'] == 999]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y8SjNWUkfYD0"},"outputs":[],"source":["df['Loan Sequence Number']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BRLMRZbifYD0"},"outputs":[],"source":["df[df['Loan Sequence Number'] == 'F20Q41283775']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GpZjVKBYZkU7"},"outputs":[],"source":["df.isna().sum()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UGYNBpdpZkU7"},"outputs":[],"source":["#Original Combined Loan-to-Value (CLTV)\n","#這是一個數值型欄位，反映貸款金額相對於房屋價值的比例。這是一個重要的財務指標，用於衡量借款人的風險。\n","#使用中位數填補，因為中位數對於數據的極端值（如高 CLTV 值）更具穩定性\n","df['Original Combined Loan-to-Value (CLTV)'] = df['Original Combined Loan-to-Value (CLTV)'].fillna(df['Original Combined Loan-to-Value (CLTV)'].median())\n","#Mortgage Insurance Percentage (MI %)\n","#這也是一個數值型欄位，描述貸款中與房屋保險相關的比例。缺失值可能意味著該筆貸款未購買保險。\n","df['Mortgage Insurance Percentage (MI %)'] = df['Mortgage Insurance Percentage (MI %)'].fillna(0)\n","#Estimated Loan-to-Value (ELTV)\n","#這是一個數值型欄位，用於估算貸款金額相對於房屋價值的比例。缺失值可能與 Original Combined Loan-to-Value (CLTV) 相關。\n","df['Estimated Loan-to-Value (ELTV)'] = df['Estimated Loan-to-Value (ELTV)'].fillna(df['Original Combined Loan-to-Value (CLTV)'].fillna(df['Estimated Loan-to-Value (ELTV)'].median()))\n","# use median to fill Remaining months to legal maturity (only 2 null values)\n","df['Remaining Months to Legal Maturity'] = df['Remaining Months to Legal Maturity'].fillna(df['Remaining Months to Legal Maturity'].median())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jDRa5w18fYD0"},"outputs":[],"source":["# review columns_to_drop\n","columns_to_drop"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jPPzw4x9ZkU7"},"outputs":[],"source":["# These columns have been dropped earlier\n","#df = df.drop(columns=['Step Modification Flag'])\n","#df = df.drop(columns=['Deferred Payment Plan'])\n","#df = df.drop(columns=['Net Sales Proceeds'])\n","#df = df.drop(columns=['Actual Loss Calculation'])\n","#df = df.drop(columns=['Expenses'])\n","#df = df.drop(columns=['MI Recoveries'])\n","#df = df.drop(columns=['Defect Settlement Date'])\n","#df = df.drop(columns=['Modification Cost'])\n","#df = df.drop(columns=['Delinquent Accrued Interest'])\n","#df = df.drop(columns=['HARP Indicator'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZIhgNAg7ZkU8"},"outputs":[],"source":["# Fill missing values for Delinquency Due to Disaster\n","df['Delinquency Due to Disaster'] = df['Delinquency Due to Disaster'].fillna('N')\n","\n","# Fill missing values for Borrower Assistance Status Code\n","df['Borrower Assistance Status Code'] = df['Borrower Assistance Status Code'].fillna('No Assistance')\n","\n","# Fill missing values for Prepayment Penalty Mortgage (PPM) Flag\n","df['Prepayment Penalty Mortgage (PPM) Flag'] = df['Prepayment Penalty Mortgage (PPM) Flag'].fillna('N')\n","\n","# Check missing values after processing\n","print(df.isna().sum())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dgMYAJlLfYD1"},"outputs":[],"source":["# Handle Zero Balance Code\n","df['Zero Balance Code'] = df['Zero Balance Code'].fillna('Non zero balance')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sAcd8OmqfYD1"},"outputs":[],"source":["df['Zero Balance Code'] = df['Zero Balance Code'].astype('object')\n","df['Zero Balance Code'].value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8dpFVliwZkU8","scrolled":false},"outputs":[],"source":["print(df.info())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PGYAt_XWfYD1"},"outputs":[],"source":["# Group by the loan identifier and count occurrences of 'Current Status' == 2\n","occurrence_status_2 = (\n","    df[df['Current Loan Delinquency Status'] == 2]\n","    .groupby('Loan Sequence Number')  # Replace with your loan identifier column\n","    .size()\n","    .rename('Occurrence_status_2')  # Rename the resulting series\n",")\n","\n","# Merge the counts back to the original DataFrame\n","df = df.merge(occurrence_status_2, on='Loan Sequence Number', how='left')\n","\n","# Fill NaN values with 0 (loans that never have 'Current Status' == 2)\n","df['Occurrence_status_2'] = df['Occurrence_status_2'].fillna(0).astype(int)\n","\n","# Display the updated DataFrame\n","print(df.head())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yjInmDgEZkU8","scrolled":true},"outputs":[],"source":["# Step 1: Filter records where Current Loan Delinquency Status is 2\n","filtered_data = df[df['Current Loan Delinquency Status'] == 2]\n","\n","# Step 2: Handle missing values in Next Month Status\n","rows_before = filtered_data.shape[0]\n","filtered_data = filtered_data.dropna(subset=['Next Month Status'])\n","rows_after = filtered_data.shape[0]\n","print(f\"Rows before drop: {rows_before}, Rows after drop: {rows_after}, Rows removed: {rows_before - rows_after}\")\n","\n","# Step 3: Check for duplicates and remove if necessary\n","duplicates = filtered_data.duplicated(subset=['Loan Sequence Number', 'Monthly Reporting Period'])\n","print(f\"Number of duplicates: {duplicates.sum()}\")\n","filtered_data = filtered_data.drop_duplicates(subset=['Loan Sequence Number', 'Monthly Reporting Period'])\n","\n","# Step 4: Verify no missing values remain\n","print(filtered_data.isna().sum())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vyQlgM4sZkU8"},"outputs":[],"source":["filtered_data.info()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jOl3_1UVZkU8"},"outputs":[],"source":["#filtered_data = filtered_data.drop(['Loan Sequence Number', 'Monthly Reporting Period'], axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eGgu7Sczufzt"},"outputs":[],"source":["# Check if there is any duplicate values\n","# duplicates = filtered_data.duplicated(subset=['Loan Sequence Number', 'Monthly Reporting Period'])\n","# print(f\"Number of duplicates: {duplicates.sum()}\")\n","# filtered_data = filtered_data.drop_duplicates(subset=['Loan Sequence Number', 'Monthly Reporting Period'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GHxWmmVvZkU8"},"outputs":[],"source":["# 確認類別型欄位\n","# Select columns with object data type\n","categorical_columns = filtered_data.select_dtypes(include=['object']).columns\n","\n","# Drop the specific columns by filtering out their names\n","categorical_columns = [col for col in categorical_columns if col not in ['Loan Sequence Number', 'Monthly Reporting Period']]\n","\n","print(f\"Categorical columns: {categorical_columns}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pdtzWlnuZkU8"},"outputs":[],"source":["# 將類別型欄位轉換為 Dummy Variables\n","filtered_data_dummies = pd.get_dummies(filtered_data, columns=categorical_columns, drop_first=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DhoXB4-EZkU8"},"outputs":[],"source":["filtered_data_dummies.info()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eDCTE1DLZkU8"},"outputs":[],"source":["filtered_data_dummies.columns"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ArkdCTOefYD3"},"outputs":[],"source":["filtered_data_dummies_before_201901 = filtered_data_dummies[filtered_data_dummies['Monthly Reporting Period'] < '2019-01']\n","filtered_data_dummies_after_201901 = filtered_data_dummies[filtered_data_dummies['Monthly Reporting Period'] >= '2019-01']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Xm_1VDXVfYD3"},"outputs":[],"source":["filtered_data_dummies_before_201901_copy = filtered_data_dummies_before_201901.copy()\n","filtered_data_dummies_after_201901_copy = filtered_data_dummies_after_201901.copy()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BFIuGdqUfYD4"},"outputs":[],"source":["filtered_data_dummies_before_201901 = filtered_data_dummies_before_201901.drop(['Loan Sequence Number', 'Monthly Reporting Period'], axis=1)\n","filtered_data_dummies_after_201901 = filtered_data_dummies_after_201901.drop(['Loan Sequence Number', 'Monthly Reporting Period'], axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PYbBpnIcfYD4"},"outputs":[],"source":["filtered_data_dummies_before_201901.info()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TiVxoaG8fYD4"},"outputs":[],"source":["filtered_data_dummies_after_201901.info()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VPctGUb_ZkU8"},"outputs":[],"source":["# Import necessary libraries\n","import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import classification_report, confusion_matrix"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fr4JJGyXZkU8"},"outputs":[],"source":["#filtered_data_dummies = filtered_data_dummies[filtered_data_dummies['Current Loan Delinquency Status'] == 2]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R4xBXCTcZkU9"},"outputs":[],"source":["# Assuming 'target' is your target variable and the rest are features\n","X = filtered_data_dummies_before_201901.drop('Next Month Status', axis=1)  # Feature columns\n","y = filtered_data_dummies_before_201901['Next Month Status']  # Target variable (loan delinquency categories)\n","\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Standardize the feature data (optional but recommended for some models)\n","scaler = StandardScaler()\n","X_train_scaled = scaler.fit_transform(X_train)\n","X_test_scaled = scaler.transform(X_test)\n","\n","# Initialize the multinomial logistic regression model\n","model = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000)\n","\n","# Train the model\n","model.fit(X_train_scaled, y_train)\n","\n","# Make predictions\n","y_pred = model.predict(X_test_scaled)\n","\n","# Evaluate the model\n","print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n","print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QLGgynebfYD4"},"outputs":[],"source":["# Assuming 'target' is your target variable and the rest are features\n","X = filtered_data_dummies_after_201901.drop('Next Month Status', axis=1)  # Feature columns\n","y = filtered_data_dummies_after_201901['Next Month Status']  # Target variable (loan delinquency categories)\n","\n","# Split the data into training and testing sets\n","#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Standardize the feature data (optional but recommended for some models)\n","scaler = StandardScaler()\n","X_scaled = scaler.fit_transform(X)\n","#X_test_scaled = scaler.transform(X_test)\n","\n","# Initialize the multinomial logistic regression model\n","#model = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000)\n","\n","# Train the model\n","#model.fit(X_train_scaled, y_train)\n","\n","# Make predictions\n","y_pred = model.predict(X_scaled)\n","\n","# Evaluate the model\n","print(\"Classification Report:\\n\", classification_report(y, y_pred))\n","print(\"Confusion Matrix:\\n\", confusion_matrix(y, y_pred))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6ZJV2YDAZkU9"},"outputs":[],"source":["# Check the feature importance\n","# Extract the coefficients for each class\n","coefficients = model.coef_\n","\n","# Create a DataFrame to view the feature importance\n","coeff_df = pd.DataFrame(coefficients, columns=X.columns)\n","\n","# Display feature importance for each class\n","coeff_df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bg6C4NeyZkU9"},"outputs":[],"source":["# You can also compute the absolute value of coefficients to see the magnitude of importance\n","feature_importance = coeff_df.abs().mean(axis=0).sort_values(ascending=False)\n","\n","# Display the importance of each feature\n","print(\"Feature Importance (average absolute coefficient values):\")\n","print(feature_importance)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VzyNgXh3ZkU9"},"outputs":[],"source":["feature_importance_top30 = feature_importance.nlargest(30)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sq9_m-XRZkVA"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","# Plot the absolute values of the coefficients for feature importance\n","plt.figure(figsize=(10, 6))\n","feature_importance_top30.sort_values().plot(kind='barh')\n","plt.title('Feature Importance based on Coefficients (Mean Absolute Value)')\n","plt.xlabel('Importance')\n","plt.ylabel('Features')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6lmp9bMDfYD5"},"outputs":[],"source":["remove_feature = feature_importance[feature_importance == 0].index\n","remove_feature"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XrwZQZH7fYD6"},"outputs":[],"source":["filtered_data_dummies_before_201901_2 = filtered_data_dummies_before_201901.drop(remove_feature, axis=1)\n","filtered_data_dummies_after_201901_2 = filtered_data_dummies_after_201901.drop(remove_feature, axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OLbV9DzwfYD6"},"outputs":[],"source":["# Assuming 'target' is your target variable and the rest are features\n","X = filtered_data_dummies_before_201901_2.drop('Next Month Status', axis=1)  # Feature columns\n","y = filtered_data_dummies_before_201901_2['Next Month Status']  # Target variable (loan delinquency categories)\n","\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Standardize the feature data (optional but recommended for some models)\n","scaler = StandardScaler()\n","X_train_scaled = scaler.fit_transform(X_train)\n","X_test_scaled = scaler.transform(X_test)\n","\n","# Initialize the multinomial logistic regression model\n","model = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000)\n","\n","# Train the model\n","model.fit(X_train_scaled, y_train)\n","\n","# Make predictions\n","y_pred = model.predict(X_test_scaled)\n","\n","# Evaluate the model\n","print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n","print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bjmNROtJfYD6"},"outputs":[],"source":["# Use all of the training data (before 2019 Jan) and retrain the model\n","X_train = filtered_data_dummies_before_201901_2.drop('Next Month Status', axis=1)\n","y_train = filtered_data_dummies_before_201901_2['Next Month Status']\n","\n","X_test = filtered_data_dummies_after_201901_2.drop('Next Month Status', axis=1)\n","y_test = filtered_data_dummies_after_201901_2['Next Month Status']\n","\n","# Standardize the feature data (optional but recommended for some models)\n","scaler = StandardScaler()\n","X_train_scaled = scaler.fit_transform(X_train)\n","X_test_scaled = scaler.transform(X_test)\n","\n","# Initialize the multinomial logistic regression model\n","model = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000)\n","\n","# Train the model\n","model.fit(X_train_scaled, y_train)\n","\n","# Make predictions\n","y_pred = model.predict(X_test_scaled)\n","\n","# Evaluate the model\n","print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n","print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))"]},{"cell_type":"markdown","metadata":{"id":"5Tw7mPDmfYD6"},"source":["## Supplemental data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Px0FL3lOfYD6"},"outputs":[],"source":["df_fmhpi = pd.read_csv('fmhpi_master_file.csv')\n","df_fmhpi.info()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aAn1NLRufYD6"},"outputs":[],"source":["df_fmhpi['GEO_Type'].unique()\n","# A Core-Based Statistical Area (CBSA) is a geographic region that includes both metropolitan statistical areas (MSAs)\n","# and micropolitan statistical areas (MSAs), while an MSA is a type of CBSA"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BX08H0FyfYD6"},"outputs":[],"source":["df_fmhpi_CA = df_fmhpi[df_fmhpi['GEO_Name'] == 'CA']\n","df_fmhpi_CA['YearMonth'] = df_fmhpi_CA['Year'].astype(str) + '-' + df_fmhpi_CA['Month'].astype(str).str.zfill(2)\n","df_fmhpi_CA"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KsHjjfAMfYD7"},"outputs":[],"source":["df_fmhpi_CA = df_fmhpi_CA.sort_values('YearMonth')\n","\n","plt.figure(figsize=(12, 6))\n","sns.lineplot(x='YearMonth', y='Index_SA', data=df_fmhpi_CA, marker='o')\n","\n","# Customize the plot\n","plt.title('House Index in California', fontsize=16)\n","plt.xlabel('Time (Year-Month)', fontsize=12)\n","plt.ylabel('Index_SA', fontsize=12)\n","plt.xticks(rotation=45)  # Rotate x-axis labels for better visibility\n","plt.grid(True)\n","plt.tight_layout()\n","\n","# Show the plot\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DrLX-1EsfYD7"},"outputs":[],"source":["df_fmhpi_merge_before_201901 = filtered_data_dummies_before_201901_copy.merge(df_fmhpi_CA, \\\n","                         left_on='Monthly Reporting Period', \\\n","                        right_on='YearMonth',\\\n","                        how='left')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ukm5la5tfYD7"},"outputs":[],"source":["df_fmhpi_merge_before_201901_copy = df_fmhpi_merge_before_201901.copy()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0K3pgGhRfYD7"},"outputs":[],"source":["df_fmhpi_merge_after_201901 = filtered_data_dummies_after_201901_copy.merge(df_fmhpi_CA, \\\n","                         left_on='Monthly Reporting Period', \\\n","                        right_on='YearMonth',\\\n","                        how='left')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p-ijKAZYfYD7"},"outputs":[],"source":["df_fmhpi_merge_after_201901_copy = df_fmhpi_merge_after_201901.copy()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YWJluvj6fYD7"},"outputs":[],"source":["df_fmhpi_merge_before_201901"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Uh1rOGHffYD7"},"outputs":[],"source":["df_fmhpi_merge_after_201901"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"slGFwLZ5fYD7"},"outputs":[],"source":["df_fmhpi_merge_before_201901 = df_fmhpi_merge_before_201901.drop(['Year', 'Month', 'GEO_Type', 'GEO_Name', 'GEO_Code', 'YearMonth', 'Monthly Reporting Period', 'Loan Sequence Number'], axis=1)\n","df_fmhpi_merge_before_201901"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g59k6wMtfYD8"},"outputs":[],"source":["df_fmhpi_merge_after_201901 = df_fmhpi_merge_after_201901.drop(['Year', 'Month', 'GEO_Type', 'GEO_Name', 'GEO_Code', 'YearMonth', 'Monthly Reporting Period', 'Loan Sequence Number'], axis=1)\n","df_fmhpi_merge_after_201901"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aVXyWqpYfYD8"},"outputs":[],"source":["df['Loan Sequence Number']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tseLErhgfYD8"},"outputs":[],"source":["X = df_fmhpi_merge_before_201901.drop('Next Month Status', axis=1)  # Feature columns\n","y = df_fmhpi_merge_before_201901['Next Month Status']  # Target variable (loan delinquency categories)\n","\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Standardize the feature data (optional but recommended for some models)\n","scaler = StandardScaler()\n","X_train_scaled = scaler.fit_transform(X_train)\n","X_test_scaled = scaler.transform(X_test)\n","\n","# Initialize the multinomial logistic regression model\n","model = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000)\n","\n","# Train the model\n","model.fit(X_train_scaled, y_train)\n","\n","# Make predictions\n","y_pred = model.predict(X_test_scaled)\n","\n","# Evaluate the model\n","print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n","print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dY9AFa3qfYD8"},"outputs":[],"source":["X_train = df_fmhpi_merge_before_201901.drop('Next Month Status', axis=1)\n","y_train = df_fmhpi_merge_before_201901['Next Month Status']\n","\n","X_test = df_fmhpi_merge_after_201901.drop('Next Month Status', axis=1)\n","y_test = df_fmhpi_merge_after_201901['Next Month Status']\n","\n","# Standardize the feature data (optional but recommended for some models)\n","scaler = StandardScaler()\n","X_train_scaled = scaler.fit_transform(X_train)\n","X_test_scaled = scaler.transform(X_test)\n","\n","# Initialize the multinomial logistic regression model\n","model = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000)\n","\n","# Train the model\n","model.fit(X_train_scaled, y_train)\n","\n","# Make predictions\n","y_pred = model.predict(X_test_scaled)\n","\n","# Evaluate the model\n","print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n","print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H0LNiNmnfYD8"},"outputs":[],"source":["# check the feature improtance\n","coefficients = model.coef_\n","\n","# Create a DataFrame to view the feature importance\n","coeff_df = pd.DataFrame(coefficients, columns=X_train.columns)\n","\n","# Display feature importance for each class\n","coeff_df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"90anPkevfYD8"},"outputs":[],"source":["feature_importance = coeff_df.abs().mean(axis=0).sort_values(ascending=False)\n","\n","# Display the importance of each feature\n","print(\"Feature Importance (average absolute coefficient values):\")\n","print(feature_importance)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K410j9FrfYD9"},"outputs":[],"source":["feature_importance_top30 = feature_importance.nlargest(30)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZlKKwwFxfYD9"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","# Plot the absolute values of the coefficients for feature importance\n","plt.figure(figsize=(10, 6))\n","feature_importance_top30.sort_values().plot(kind='barh')\n","plt.title('Feature Importance based on Coefficients (Mean Absolute Value)')\n","plt.xlabel('Importance')\n","plt.ylabel('Features')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"bmRtB8zYfYD9"},"source":["## Supplemental data_2: Unemployment Data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ubTDaAsTfYD9"},"outputs":[],"source":["# load the unemployment data (for California)\n","unemployment = pd.read_csv('CAUR.csv')\n","unemployment.info()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AeLRnIoPfYD9"},"outputs":[],"source":["unemployment"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U7s6smfvfYD9"},"outputs":[],"source":["unemployment['YearMonth'] = pd.to_datetime(unemployment['DATE']).dt.strftime('%Y-%m')\n","\n","print(unemployment[['DATE', 'YearMonth']].head())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yrRDo7DxfYD9"},"outputs":[],"source":["# take a look\n","unemployment = unemployment.sort_values('YearMonth')\n","\n","plt.figure(figsize=(12, 6))\n","sns.lineplot(x='YearMonth', y='CAUR', data=unemployment[unemployment['YearMonth'] > '1999-01'], marker='o')\n","\n","# Customize the plot\n","plt.title('Unemployment Rate Trend Over Time in California', fontsize=16)\n","plt.xlabel('Time (Year-Month)', fontsize=12)\n","plt.ylabel('Unemployment Rate (%)', fontsize=12)\n","plt.xticks(rotation=45)  # Rotate x-axis labels for better visibility\n","plt.grid(True)\n","plt.tight_layout()\n","\n","# Show the plot\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SIbN8AFJfYD9"},"outputs":[],"source":["# Merge the unemployment data into the main training data\n","df_unemployment_merge_before_201901 = df_fmhpi_merge_before_201901_copy.merge(unemployment, \\\n","                         left_on='Monthly Reporting Period', \\\n","                        right_on='YearMonth',\\\n","                        how='left')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nOZ57nONfYD-"},"outputs":[],"source":["df_unemployment_merge_before_201901_copy = df_unemployment_merge_before_201901.copy()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8jIzKeVgfYD-"},"outputs":[],"source":["df_unemployment_merge_after_201901 = df_fmhpi_merge_after_201901_copy.merge(unemployment, \\\n","                         left_on='Monthly Reporting Period', \\\n","                        right_on='YearMonth',\\\n","                        how='left')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B3WEasIGfYD-"},"outputs":[],"source":["df_unemployment_merge_after_201901_copy = df_unemployment_merge_after_201901.copy()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yY_MiAPqfYD-"},"outputs":[],"source":["df_unemployment_merge_before_201901"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hNaxVNgBfYD-"},"outputs":[],"source":["df_unemployment_merge_before_201901 = df_unemployment_merge_before_201901.drop(['Year', 'Month', 'GEO_Type', 'GEO_Name', 'GEO_Code', 'DATE', 'YearMonth_x', 'YearMonth_y', 'Monthly Reporting Period', 'Loan Sequence Number'], axis=1)\n","df_unemployment_merge_before_201901"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uLXNlKYSfYD-"},"outputs":[],"source":["df_unemployment_merge_after_201901 = df_unemployment_merge_after_201901.drop(['Year', 'Month', 'GEO_Type', 'GEO_Name', 'GEO_Code', 'DATE', 'YearMonth_x', 'YearMonth_y', 'Monthly Reporting Period', 'Loan Sequence Number'], axis=1)\n","df_unemployment_merge_after_201901"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mFfmYT2AfYD_"},"outputs":[],"source":["X = df_unemployment_merge_before_201901.drop('Next Month Status', axis=1)  # Feature columns\n","y = df_unemployment_merge_before_201901['Next Month Status']  # Target variable (loan delinquency categories)\n","\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Standardize the feature data (optional but recommended for some models)\n","scaler = StandardScaler()\n","X_train_scaled = scaler.fit_transform(X_train)\n","X_test_scaled = scaler.transform(X_test)\n","\n","# Initialize the multinomial logistic regression model\n","model = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000)\n","\n","# Train the model\n","model.fit(X_train_scaled, y_train)\n","\n","# Make predictions\n","y_pred = model.predict(X_test_scaled)\n","\n","# Evaluate the model\n","print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n","print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Jb3alBG6fYD_"},"outputs":[],"source":["X_train = df_unemployment_merge_before_201901.drop('Next Month Status', axis=1)\n","y_train = df_unemployment_merge_before_201901['Next Month Status']\n","\n","X_test = df_unemployment_merge_after_201901.drop('Next Month Status', axis=1)\n","y_test = df_unemployment_merge_after_201901['Next Month Status']\n","\n","# Standardize the feature data (optional but recommended for some models)\n","scaler = StandardScaler()\n","X_train_scaled = scaler.fit_transform(X_train)\n","X_test_scaled = scaler.transform(X_test)\n","\n","# Initialize the multinomial logistic regression model\n","model = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000)\n","\n","# Train the model\n","model.fit(X_train_scaled, y_train)\n","\n","# Make predictions\n","y_pred = model.predict(X_test_scaled)\n","\n","# Evaluate the model\n","print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n","print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))"]},{"cell_type":"markdown","metadata":{"id":"fa_lFSP8fYD_"},"source":["## YearMonth"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W4un7RojfYD_"},"outputs":[],"source":["df_201903 = df_unemployment_merge_after_201901_copy[df_unemployment_merge_after_201901_copy['Monthly Reporting Period'] == '2019-03']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FAyiVz0bfYD_"},"outputs":[],"source":["df_201903.info()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yyavaC78fYD_"},"outputs":[],"source":["df_201903.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7ghDUR3ifYD_"},"outputs":[],"source":["df_201903 = df_201903.drop(['Year', 'Month', 'GEO_Type', 'GEO_Name', 'GEO_Code', 'DATE', 'YearMonth_x', 'YearMonth_y', 'Monthly Reporting Period', 'Loan Sequence Number'], axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c0rcFcZHfYEA"},"outputs":[],"source":["X = df_201903.drop('Next Month Status', axis=1)  # Feature columns\n","y = df_201903['Next Month Status']  # Target variable (loan delinquency categories)\n","\n","\n","# Standardize the feature data\n","scaler = StandardScaler()\n","X_scaled = scaler.fit_transform(X)\n","\n","# Make predictions\n","y_pred = model.predict(X_scaled)\n","\n","# Evaluate the model\n","print(\"Classification Report:\\n\", classification_report(y, y_pred))\n","print(\"Confusion Matrix:\\n\", confusion_matrix(y, y_pred))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iDxkP_bofYEA"},"outputs":[],"source":["from sklearn.metrics import mean_squared_error\n","import numpy as np\n","\n","# Calculate RMSE\n","rmse = np.sqrt(mean_squared_error(y, y_pred))\n","\n","print(f\"Root Mean Squared Error (RMSE): {rmse}\")"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.6"}},"nbformat":4,"nbformat_minor":0}